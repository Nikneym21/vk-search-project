#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ CSV —Ñ–∞–π–ª–∞—Ö
"""

import sys
import os
import json
import pandas as pd
from collections import Counter

def analyze_duplicates(csv_file):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ CSV —Ñ–∞–π–ª–µ"""
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –î–£–ë–õ–ò–ö–ê–¢–û–í: {csv_file}")
    print("="*60)
    
    try:
        df = pd.read_csv(csv_file)
        print(f"üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ä–∞–∑–Ω—ã–º –ø–æ–ª—è–º
        print(f"\nüìã –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
        
        # –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ (owner_id, id)
        df['post_key'] = df['owner_id'].astype(str) + '_' + df['id'].astype(str)
        duplicate_keys = df[df.duplicated(subset=['post_key'], keep=False)]
        print(f"   –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ (owner_id, id): {len(duplicate_keys)} —Å—Ç—Ä–æ–∫")
        
        # –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ç–µ–∫—Å—Ç—É
        text_duplicates = df[df.duplicated(subset=['text'], keep=False)]
        print(f"   –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ç–µ–∫—Å—Ç—É: {len(text_duplicates)} —Å—Ç—Ä–æ–∫")
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—Å—Ç—ã
        unique_posts = df.drop_duplicates(subset=['post_key'])
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤: {len(unique_posts)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        if len(duplicate_keys) > 0:
            print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
            duplicate_groups = df.groupby('post_key').filter(lambda x: len(x) > 1)
            for i, (key, group) in enumerate(duplicate_groups.groupby('post_key')[:3]):
                print(f"   –ì—Ä—É–ø–ø–∞ {i+1} (–∫–ª—é—á: {key}): {len(group)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
                for j, row in group.iterrows():
                    text = row['text'][:50] + "..." if len(row['text']) > 50 else row['text']
                    print(f"     {j}: {text}")
        
        return {
            'total': len(df),
            'duplicate_keys': len(duplicate_keys),
            'text_duplicates': len(text_duplicates),
            'unique': len(unique_posts)
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {csv_file}: {e}")
        return None

def test_filter_without_dedup(csv_file, keywords, exact_match=True):
    """–¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    print(f"\nüß™ –¢–ï–°–¢ –§–ò–õ–¨–¢–†–ê–¶–ò–ò –ë–ï–ó –£–î–ê–õ–ï–ù–ò–Ø –î–£–ë–õ–ò–ö–ê–¢–û–í")
    print("="*60)
    
    try:
        df = pd.read_csv(csv_file)
        posts = []
        
        for _, row in df.iterrows():
            post = {
                'id': row.get('id', 0),
                'owner_id': row.get('owner_id', 0),
                'text': row.get('text', ''),
                'date': row.get('date', 0)
            }
            posts.append(post)
        
        print(f"üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        print(f"   –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {len(posts)}")
        print(f"   –ö–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(keywords)}")
        
        # –ü—Ä–æ—Å—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        filtered_posts = []
        keyword_matches = {}
        
        for post in posts:
            text = post.get('text', '')
            for keyword in keywords:
                if keyword.lower() in text.lower():
                    filtered_posts.append(post)
                    keyword_matches[keyword] = keyword_matches.get(keyword, 0) + 1
                    break  # –û–¥–∏–Ω –ø–æ—Å—Ç –º–æ–∂–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ–º—É –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É
        
        print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"   –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤: {len(filtered_posts)}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤: {len(set((p['owner_id'], p['id']) for p in filtered_posts))}")
        
        if keyword_matches:
            print(f"\nüìã –°–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º:")
            for keyword, count in sorted(keyword_matches.items(), key=lambda x: x[1], reverse=True):
                print(f"   '{keyword}': {count} –ø–æ—Å—Ç–æ–≤")
        
        return len(filtered_posts)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {e}")
        return 0

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üß™ –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±–∞ —Ñ–∞–π–ª–∞
    csv_files = [
        'data/results/search_20250726_045350.csv',
        'data/results/search_20250726_051718.csv'
    ]
    
    meta_files = [
        'data/results/search_20250726_045350.meta.json',
        'data/results/search_20250726_051718.meta.json'
    ]
    
    for csv_file, meta_file in zip(csv_files, meta_files):
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        dup_stats = analyze_duplicates(csv_file)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        try:
            with open(meta_file, 'r', encoding='utf-8') as f:
                meta = json.load(f)
            keywords = meta.get('keywords', [])
            expected_count = meta.get('count', 0)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {meta_file}: {e}")
            continue
        
        print(f"\nüìã –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {expected_count} –ø–æ—Å—Ç–æ–≤")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        actual_count = test_filter_without_dedup(csv_file, keywords)
        
        print(f"\nüéØ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ:")
        print(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: {expected_count}")
        print(f"   –ü–æ–ª—É—á–µ–Ω–æ: {actual_count}")
        print(f"   –†–∞–∑–Ω–∏—Ü–∞: {actual_count - expected_count}")
        
        if dup_stats:
            print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤: {dup_stats['unique']}")
            print(f"   –î—É–±–ª–∏–∫–∞—Ç–æ–≤: {dup_stats['duplicate_keys']}")

if __name__ == "__main__":
    main() 