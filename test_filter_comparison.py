#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
"""

import sys
import os
import json
import pandas as pd
import asyncio
import re

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

class SimpleFilterPlugin:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è FilterPlugin –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.name = "SimpleFilterPlugin"
    
    def _extract_post_text(self, post):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –ø–æ—Å—Ç–∞"""
        text = post.get('text', '')
        if not text:
            text = post.get('message', '')
        if not text:
            text = post.get('content', '')
        return text
    
    def _basic_text_clean(self, text):
        """–ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return ""
        # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        text = re.sub(r'[^\w\s]', ' ', text)
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text).strip()
        return text.lower()
    
    def _check_keyword_match(self, text, keyword, exact_match):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–∫—Å—Ç–∞ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É"""
        if not text or not keyword:
            return False
        
        cleaned_text = self._basic_text_clean(text)
        keyword_lower = keyword.lower()
        
        if exact_match:
            # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–≤–∫–ª—é—á–∞—è –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤)
            pattern = r'\b' + re.escape(keyword_lower) + r'\b'
            return bool(re.search(pattern, cleaned_text))
        else:
            # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            return keyword_lower in cleaned_text
    
    async def filter_posts_comprehensive_parallel(self, posts, keywords, exact_match=True):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤"""
        if not posts:
            return []
        
        print(f"üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è {len(posts)} –ø–æ—Å—Ç–æ–≤ –ø–æ {len(keywords)} –∫–ª—é—á–∞–º")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        tasks = []
        chunk_size = max(1, len(posts) // 10)
        
        for i in range(0, len(posts), chunk_size):
            chunk = posts[i:i + chunk_size]
            task = self._process_chunk_parallel(chunk, keywords, exact_match)
            tasks.append(task)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*tasks)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        filtered_posts = []
        for result in results:
            filtered_posts.extend(result)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_posts = self.filter_unique_posts(filtered_posts)
        
        print(f"‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(posts)} -> {len(unique_posts)}")
        return unique_posts
    
    async def _process_chunk_parallel(self, chunk, keywords, exact_match):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ –ø–æ—Å—Ç–æ–≤"""
        filtered_chunk = []
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞ –≤ —á–∞–Ω–∫–µ
        post_tasks = []
        for post in chunk:
            task = self._process_single_post_parallel(post, keywords, exact_match)
            post_tasks.append(task)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–æ—Å—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*post_tasks, return_exceptions=True)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result in results:
            if isinstance(result, dict) and result:
                filtered_chunk.append(result)
            elif isinstance(result, Exception):
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞: {result}")
        
        return filtered_chunk
    
    async def _process_single_post_parallel(self, post, keywords, exact_match):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –ø–æ—Å—Ç–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
            text = self._extract_post_text(post)
            if not text:
                return None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            for keyword in keywords:
                if self._check_keyword_match(text, keyword, exact_match):
                    return post
            
            return None
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞: {e}")
            return None
    
    def filter_unique_posts(self, posts):
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –ø–æ (owner_id, post_id)"""
        if not posts:
            return []
        
        seen = set()
        unique = []
        
        for post in posts:
            owner_id = post.get('owner_id')
            post_id = post.get('id') or post.get('post_id')
            
            if owner_id is not None and post_id is not None:
                key = (owner_id, post_id)
                if key not in seen:
                    seen.add(key)
                    unique.append(post)
        
        print(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤: {len(posts)} -> {len(unique)}")
        return unique

def load_csv_as_posts(csv_file):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV —Ñ–∞–π–ª –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –ø–æ—Å—Ç–æ–≤"""
    print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º {csv_file}...")
    
    try:
        df = pd.read_csv(csv_file)
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –ø–æ—Å—Ç–æ–≤ (–∫–∞–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç VK API)
        posts = []
        for _, row in df.iterrows():
            post = {
                'id': row.get('id', 0),
                'owner_id': row.get('owner_id', 0),
                'text': row.get('text', ''),
                'date': row.get('date', 0),
                'likes': {'count': row.get('likes', 0)},
                'comments': {'count': row.get('comments', 0)},
                'reposts': {'count': row.get('reposts', 0)},
                'views': {'count': row.get('views', 0)}
            }
            posts.append(post)
        
        print(f"   –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ {len(posts)} –ø–æ—Å—Ç–æ–≤")
        return posts
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {csv_file}: {e}")
        return []

def load_meta_data(meta_file):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ meta.json —Ñ–∞–π–ª–∞"""
    try:
        with open(meta_file, 'r', encoding='utf-8') as f:
            meta = json.load(f)
        return meta
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {meta_file}: {e}")
        return None

async def test_single_file(meta_file, filter_plugin):
    """–¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    print(f"\n{'='*60}")
    print(f"üìã –¢–ï–°–¢ –§–ê–ô–õ–ê: {meta_file}")
    print(f"{'='*60}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    meta = load_meta_data(meta_file)
    if not meta:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
        return
    
    keywords = meta.get('keywords', [])
    csv_file = meta.get('filepath', '')
    expected_count = meta.get('count', 0)
    exact_match = meta.get('exact_match', False)
    
    print(f"üìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
    print(f"   –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {expected_count} –ø–æ—Å—Ç–æ–≤")
    print(f"   –ö–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(keywords)}")
    print(f"   Exact match: {exact_match}")
    print(f"   CSV —Ñ–∞–π–ª: {csv_file}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç—ã –∏–∑ CSV
    if not csv_file or not os.path.exists(csv_file):
        print("‚ùå CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    posts = load_csv_as_posts(csv_file)
    if not posts:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å—Ç—ã")
        return
    
    print(f"\nüîç –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:")
    for i, keyword in enumerate(keywords[:5], 1):
        print(f"   {i}. {keyword}")
    if len(keywords) > 5:
        print(f"   ... –∏ –µ—â–µ {len(keywords) - 5} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
    print(f"\nüîç –¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:")
    try:
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏–∑ meta.json
        print(f"   –ó–∞–ø—É—Å–∫ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å exact_match={exact_match}...")
        filtered_posts = await filter_plugin.filter_posts_comprehensive_parallel(
            posts, keywords, exact_match=exact_match
        )
        
        actual_count = len(filtered_posts)
        difference = actual_count - expected_count
        
        print(f"\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢:")
        print(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: {expected_count} –ø–æ—Å—Ç–æ–≤")
        print(f"   –ü–æ–ª—É—á–µ–Ω–æ: {actual_count} –ø–æ—Å—Ç–æ–≤")
        print(f"   –†–∞–∑–Ω–∏—Ü–∞: {difference}")
        
        if abs(difference) <= 5:
            print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –±–ª–∏–∑–æ–∫ –∫ –æ–∂–∏–¥–∞–µ–º–æ–º—É!")
        elif difference > 0:
            print(f"   ‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω–æ –±–æ–ª—å—à–µ –ø–æ—Å—Ç–æ–≤ —á–µ–º –æ–∂–∏–¥–∞–ª–æ—Å—å")
        else:
            print(f"   ‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω–æ –º–µ–Ω—å—à–µ –ø–æ—Å—Ç–æ–≤ —á–µ–º –æ–∂–∏–¥–∞–ª–æ—Å—å")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        if filtered_posts:
            print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤:")
            for i, post in enumerate(filtered_posts[:3]):
                text = post.get('text', '')[:100]
                owner_id = post.get('owner_id', 0)
                post_id = post.get('id', 0)
                print(f"   {i+1}. [ID: {owner_id}_{post_id}] {text}...")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º:")
        for keyword in keywords[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            keyword_posts = []
            for post in posts:
                text = filter_plugin._extract_post_text(post)
                if filter_plugin._check_keyword_match(text, keyword, exact_match=exact_match):
                    keyword_posts.append(post)
            print(f"   '{keyword}': {len(keyword_posts)} –ø–æ—Å—Ç–æ–≤")
        
        return {
            'file': meta_file,
            'expected': expected_count,
            'actual': actual_count,
            'difference': difference,
            'keywords_count': len(keywords),
            'posts_count': len(posts)
        }
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return None

async def test_filter_comparison():
    """–¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞"""
    print("üß™ –¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Ñ–∞–π–ª–∞–º")
    
    # –°–æ–∑–¥–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–ª–∞–≥–∏–Ω
    filter_plugin = SimpleFilterPlugin()
    
    # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    meta_files = [
        'data/results/search_20250726_045350.meta.json',
        'data/results/search_20250726_051718.meta.json'
    ]
    
    results = []
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –æ—Ç–¥–µ–ª—å–Ω–æ
    for meta_file in meta_files:
        result = await test_single_file(meta_file, filter_plugin)
        if result:
            results.append(result)
    
    # –°–≤–æ–¥–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\n{'='*60}")
    print(f"üìä –°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print(f"{'='*60}")
    
    total_expected = 0
    total_actual = 0
    
    for result in results:
        print(f"üìÅ {result['file']}:")
        print(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: {result['expected']} –ø–æ—Å—Ç–æ–≤")
        print(f"   –ü–æ–ª—É—á–µ–Ω–æ: {result['actual']} –ø–æ—Å—Ç–æ–≤")
        print(f"   –†–∞–∑–Ω–∏—Ü–∞: {result['difference']}")
        print(f"   –ö–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {result['keywords_count']}")
        print(f"   –ò—Å—Ö–æ–¥–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤: {result['posts_count']}")
        print()
        
        total_expected += result['expected']
        total_actual += result['actual']
    
    total_difference = total_actual - total_expected
    print(f"üéØ –ò–¢–û–ì–û:")
    print(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: {total_expected} –ø–æ—Å—Ç–æ–≤")
    print(f"   –ü–æ–ª—É—á–µ–Ω–æ: {total_actual} –ø–æ—Å—Ç–æ–≤")
    print(f"   –û–±—â–∞—è —Ä–∞–∑–Ω–∏—Ü–∞: {total_difference}")
    
    if abs(total_difference) <= 10:
        print(f"   ‚úÖ –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–ª–∏–∑–æ–∫ –∫ –æ–∂–∏–¥–∞–µ–º–æ–º—É!")
    else:
        print(f"   ‚ö†Ô∏è –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ–∂–∏–¥–∞–µ–º–æ–≥–æ")
    
    print(f"\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω")

if __name__ == "__main__":
    asyncio.run(test_filter_comparison()) 