#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ –ø–æ—Å—Ç–æ–≤
"""

import sys
import os
import json
import pandas as pd
import re

def load_csv_as_posts(csv_file):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV —Ñ–∞–π–ª –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –ø–æ—Å—Ç–æ–≤"""
    print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º {csv_file}...")
    
    try:
        df = pd.read_csv(csv_file)
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –ø–æ—Å—Ç–æ–≤
        posts = []
        for _, row in df.iterrows():
            post = {
                'id': row.get('id', 0),
                'owner_id': row.get('owner_id', 0),
                'text': row.get('text', ''),
                'date': row.get('date', 0)
            }
            posts.append(post)
        
        print(f"   –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ {len(posts)} –ø–æ—Å—Ç–æ–≤")
        return posts
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {csv_file}: {e}")
        return []

def basic_text_clean(text):
    """–ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return ""
    # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
    text = re.sub(r'[^\w\s]', ' ', text)
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s+', ' ', text).strip()
    return text.lower()

def check_keyword_match(text, keyword, exact_match):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–∫—Å—Ç–∞ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É"""
    if not text or not keyword:
        return False
    
    cleaned_text = basic_text_clean(text)
    keyword_lower = keyword.lower()
    
    if exact_match:
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–≤–∫–ª—é—á–∞—è –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤)
        pattern = r'\b' + re.escape(keyword_lower) + r'\b'
        return bool(re.search(pattern, cleaned_text))
    else:
        # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        return keyword_lower in cleaned_text

def analyze_text_samples(csv_file, keywords, exact_match=True):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—Ä–∞–∑—Ü—ã —Ç–µ–∫—Å—Ç–∞"""
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –¢–ï–ö–°–¢–ê: {csv_file}")
    print("="*60)
    
    posts = load_csv_as_posts(csv_file)
    if not posts:
        return
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {len(posts)}")
    print(f"   –ö–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(keywords)}")
    print(f"   Exact match: {exact_match}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø–æ—Å—Ç–æ–≤
    print(f"\nüìù –û–±—Ä–∞–∑—Ü—ã —Ç–µ–∫—Å—Ç–∞ (–ø–µ—Ä–≤—ã–µ 5 –ø–æ—Å—Ç–æ–≤):")
    for i, post in enumerate(posts[:5]):
        text = post.get('text', '')
        owner_id = post.get('owner_id', 0)
        post_id = post.get('id', 0)
        
        print(f"\n   –ü–æ—Å—Ç {i+1} [ID: {owner_id}_{post_id}]:")
        print(f"   –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç: {text[:200]}...")
        
        cleaned = basic_text_clean(text)
        print(f"   –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {cleaned[:200]}...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        matches = []
        for keyword in keywords[:3]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 3 –∫–ª—é—á–∞
            if check_keyword_match(text, keyword, exact_match):
                matches.append(keyword)
        
        if matches:
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {matches}")
        else:
            print(f"   ‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìä –û–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    total_matches = 0
    keyword_stats = {}
    
    for keyword in keywords:
        keyword_matches = 0
        for post in posts:
            if check_keyword_match(post.get('text', ''), keyword, exact_match):
                keyword_matches += 1
                total_matches += 1
        
        if keyword_matches > 0:
            keyword_stats[keyword] = keyword_matches
    
    print(f"   –í—Å–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {total_matches}")
    print(f"   –ö–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º–∏: {len(keyword_stats)}")
    
    if keyword_stats:
        print(f"\nüìã –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º–∏:")
        for keyword, count in sorted(keyword_stats.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"   '{keyword}': {count} –ø–æ—Å—Ç–æ–≤")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üß™ –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Ç–æ—Ä–æ–π —Ñ–∞–π–ª (–≥–¥–µ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
    csv_file = 'data/results/search_20250726_051718.csv'
    meta_file = 'data/results/search_20250726_051718.meta.json'
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    try:
        with open(meta_file, 'r', encoding='utf-8') as f:
            meta = json.load(f)
        keywords = meta.get('keywords', [])
        exact_match = meta.get('exact_match', True)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {meta_file}: {e}")
        return
    
    print(f"üìã –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ {meta_file}:")
    for i, keyword in enumerate(keywords, 1):
        print(f"   {i}. {keyword}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
    analyze_text_samples(csv_file, keywords, exact_match)

if __name__ == "__main__":
    main() 