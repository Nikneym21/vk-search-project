"""
–ü–ª–∞–≥–∏–Ω –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º
"""

from typing import Dict, List, Any, Optional
from datetime import datetime
import asyncio

from ...core.event_system import EventType
from ..base_plugin import BasePlugin


class FilterPlugin(BasePlugin):
    """–ü–ª–∞–≥–∏–Ω –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º"""
    
    def __init__(self):
        super().__init__()
        self.name = "FilterPlugin"
        self.version = "1.0.0"
        self.description = "–ü–ª–∞–≥–∏–Ω –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º —Å –æ—á–∏—Å—Ç–∫–æ–π —Ç–µ–∫—Å—Ç–∞"
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.config = {
            "enable_text_cleaning": True,
            "enable_exact_match": True,
            "enable_unique_filtering": True,
            "min_text_length": 3,
            "max_text_length": 10000
        }
    
    def initialize(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞–≥–∏–Ω–∞"""
        self.log_info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞–≥–∏–Ω–∞ Filter")
        
        if not self.validate_config():
            self.log_error("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–ª–∞–≥–∏–Ω–∞")
            return
        
        self.log_info("–ü–ª–∞–≥–∏–Ω Filter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        self.emit_event(EventType.PLUGIN_LOADED, {"status": "initialized"})
    
    def shutdown(self) -> None:
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø–ª–∞–≥–∏–Ω–∞"""
        self.log_info("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –ø–ª–∞–≥–∏–Ω–∞ Filter")
        
        self.emit_event(EventType.PLUGIN_UNLOADED, {"status": "shutdown"})
        self.log_info("–ü–ª–∞–≥–∏–Ω Filter –∑–∞–≤–µ—Ä—à–µ–Ω")
    
    def validate_config(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        return True
    
    def get_required_config_keys(self) -> list:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        return []
    
    def get_statistics(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–ª–∞–≥–∏–Ω–∞"""
        return {
            "enabled": self.is_enabled(),
            "config": self.get_config()
        }

    def filter_unique_posts(self, posts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –ø–æ (owner_id, post_id)
        
        Args:
            posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        """
        if not posts:
            return []
        
        seen = set()
        unique = []
        
        for post in posts:
            owner_id = post.get('owner_id')
            post_id = post.get('id') or post.get('post_id')
            
            if owner_id is not None and post_id is not None:
                key = (owner_id, post_id)
                if key not in seen:
                    seen.add(key)
                    unique.append(post)
        
        self.log_info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤: {len(posts)} -> {len(unique)}")
        return unique

    def filter_posts_by_keyword(self, posts: List[Dict[str, Any]], keyword: str, exact_match: bool = True) -> List[Dict[str, Any]]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É (–±–µ–∑ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞)
        
        Args:
            posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
            exact_match: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (True) –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ (False)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        """
        if not posts or not keyword:
            return []
        
        filtered = []
        keyword_lower = keyword.lower()
        
        for post in posts:
            text = str(post.get('text', '') or post.get('post_text', ''))
            text_lower = text.lower()
            
            if exact_match:
                # –¢–æ—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
                if keyword_lower in text_lower:
                    filtered.append(post)
            else:
                # –ß–∞—Å—Ç–∏—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ (–ø–æ —Å–ª–æ–≤–∞–º)
                words = text_lower.split()
                if keyword_lower in words:
                    filtered.append(post)
        
        self.log_info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á—É '{keyword}': {len(posts)} -> {len(filtered)}")
        return filtered

    def filter_posts_by_keyword_with_text_cleaning(self, posts: List[Dict[str, Any]], keyword: str, exact_match: bool = True) -> List[Dict[str, Any]]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É —Å –æ—á–∏—Å—Ç–∫–æ–π —Ç–µ–∫—Å—Ç–∞
        
        Args:
            posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            keyword: –ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞
            exact_match: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (True) –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ (False)
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        """
        if not posts or not keyword:
            return []
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º TextProcessingPlugin –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
            from ..text_processing.text_processing_plugin import TextProcessingPlugin
            text_plugin = TextProcessingPlugin()
            text_plugin.initialize()
            
            # –û—á–∏—â–∞–µ–º –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
            keyword_clean = text_plugin.clean_text_completely(keyword)
            
            filtered = []
            for post in posts:
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
                text = str(post.get('text', '') or post.get('post_text', ''))
                
                # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
                text_clean = text_plugin.clean_text_completely(text)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –∫–ª—é—á–∞
                if keyword_clean in text_clean:
                    filtered.append(post)
            
            text_plugin.shutdown()
            
            self.log_info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å –æ—á–∏—Å—Ç–∫–æ–π —Ç–µ–∫—Å—Ç–∞ –ø–æ –∫–ª—é—á—É '{keyword}': {len(posts)} -> {len(filtered)}")
            return filtered
            
        except Exception as e:
            self.log_error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å –æ—á–∏—Å—Ç–∫–æ–π —Ç–µ–∫—Å—Ç–∞: {e}")
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏
            return self.filter_posts_by_keyword(posts, keyword, exact_match)

    def filter_posts_by_multiple_keywords(self, posts: List[Dict[str, Any]], keywords: List[str], 
                                        exact_match: bool = True, use_text_cleaning: bool = True) -> List[Dict[str, Any]]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        
        Args:
            posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            keywords: –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            exact_match: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (True) –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ (False)
            use_text_cleaning: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        """
        if not posts or not keywords:
            return []
        
        filtered = []
        
        for post in posts:
            text = str(post.get('text', '') or post.get('post_text', ''))
            
            for keyword in keywords:
                if use_text_cleaning:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å –æ—á–∏—Å—Ç–∫–æ–π —Ç–µ–∫—Å—Ç–∞
                    temp_filtered = self.filter_posts_by_keyword_with_text_cleaning([post], keyword, exact_match)
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                    temp_filtered = self.filter_posts_by_keyword([post], keyword, exact_match)
                
                if temp_filtered:
                    filtered.append(post)
                    break  # –ù–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø–æ—Å—Ç—É
        
        self.log_info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ {len(keywords)} –∫–ª—é—á–∞–º: {len(posts)} -> {len(filtered)}")
        return filtered

    def filter_posts_comprehensive(self, posts: List[Dict[str, Any]], keywords: List[str] = None,
                                 exact_match: bool = True, use_text_cleaning: bool = True,
                                 remove_duplicates: bool = True) -> List[Dict[str, Any]]:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Ñ—Ä–∞–∑–∞–º
        
        Args:
            posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            keywords: –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            exact_match: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (True) –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ (False)
            use_text_cleaning: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–∞
            remove_duplicates: –£–¥–∞–ª—è—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
            
        Returns:
            –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        """
        if not posts:
            return []
        
        filtered = posts.copy()
        
        # 1. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        if keywords:
            if len(keywords) == 1:
                # –û–¥–∏–Ω –∫–ª—é—á
                if use_text_cleaning:
                    filtered = self.filter_posts_by_keyword_with_text_cleaning(filtered, keywords[0], exact_match)
                else:
                    filtered = self.filter_posts_by_keyword(filtered, keywords[0], exact_match)
            else:
                # –ù–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–π
                filtered = self.filter_posts_by_multiple_keywords(filtered, keywords, exact_match, use_text_cleaning)
        
        # 2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        if remove_duplicates:
            filtered = self.filter_unique_posts(filtered)
        
        self.log_info(f"–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è: {len(posts)} -> {len(filtered)}")
        return filtered 

    async def filter_posts_comprehensive_parallel(self, posts: List[Dict[str, Any]], keywords: List[str], 
                                               exact_match: bool = True) -> List[Dict[str, Any]]:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        """
        if not posts:
            return []
        
        self.log_info(f"üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è {len(posts)} –ø–æ—Å—Ç–æ–≤ –ø–æ {len(keywords)} –∫–ª—é—á–∞–º")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        tasks = []
        chunk_size = max(1, len(posts) // 10)  # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
        for i in range(0, len(posts), chunk_size):
            chunk = posts[i:i + chunk_size]
            task = self._process_chunk_parallel(chunk, keywords, exact_match)
            tasks.append(task)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*tasks)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        filtered_posts = []
        for result in results:
            filtered_posts.extend(result)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_posts = self.filter_unique_posts(filtered_posts)
        
        self.log_info(f"‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(posts)} -> {len(unique_posts)}")
        return unique_posts
    
    async def _process_chunk_parallel(self, chunk: List[Dict[str, Any]], keywords: List[str], 
                                    exact_match: bool) -> List[Dict[str, Any]]:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ –ø–æ—Å—Ç–æ–≤
        """
        filtered_chunk = []
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞ –≤ —á–∞–Ω–∫–µ
        post_tasks = []
        for post in chunk:
            task = self._process_single_post_parallel(post, keywords, exact_match)
            post_tasks.append(task)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–æ—Å—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*post_tasks, return_exceptions=True)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result in results:
            if isinstance(result, dict) and result:  # –ï—Å–ª–∏ –ø–æ—Å—Ç –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                filtered_chunk.append(result)
            elif isinstance(result, Exception):
                self.log_error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞: {result}")
        
        return filtered_chunk
    
    async def _process_single_post_parallel(self, post: Dict[str, Any], keywords: List[str], 
                                          exact_match: bool) -> Optional[Dict[str, Any]]:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –ø–æ—Å—Ç–∞
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
            text = self._extract_post_text(post)
            if not text:
                return None
            
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
            cleaned_text = await self._clean_text_async(text)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            for keyword in keywords:
                if self._check_keyword_match(cleaned_text, keyword, exact_match):
                    return post
            
            return None
            
        except Exception as e:
            self.log_error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞: {e}")
            return None
    
    async def _clean_text_async(self, text: str) -> str:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        """
        # –ü–æ–ª—É—á–∞–µ–º TextProcessingPlugin
        plugin_manager = self.get_plugin_manager()
        if plugin_manager:
            text_plugin = plugin_manager.get_plugin('text_processing')
            if text_plugin:
                return text_plugin.clean_text_completely(text)
        
        # Fallback –∫ –±–∞–∑–æ–≤–æ–π –æ—á–∏—Å—Ç–∫–µ
        return self._basic_text_clean(text)
    
    def _basic_text_clean(self, text: str) -> str:
        """
        –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ (fallback)
        """
        import re
        # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏
        text = re.sub(r'[^\w\s]', ' ', text)
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text).strip()
        return text.lower() 